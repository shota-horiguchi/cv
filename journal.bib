% First author
@article{horiguchi2023online,
    title={Online Neural Diarization of Unlimited Numbers of Speakers Using Global and Local Attractors},
    journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
    author={Horiguchi, Shota and Watanabe, Shinji and Garcia, Paola and Takashima, Yuki and Kawaguchi, Yohei},
    volume={31},
    year={2023},
    month=jan,
    pages={706-720},
    keywords={first},
    abbr={TASLP},
    abstract={A method to perform offline and online speaker diarization for an unlimited number of speakers is described in this paper. End-to-end neural diarization (EEND) has achieved overlap-aware speaker diarization by formulating it as a multi-label classification problem. It has also been extended for a flexible number of speakers by introducing speaker-wise attractors. However, the output number of speakers of attractor-based EEND is empirically capped; it cannot deal with cases where the number of speakers appearing during inference is higher than that during training because its speaker counting is trained in a fully supervised manner. Our method, EEND-GLA, solves this problem by introducing unsupervised clustering into attractor-based EEND. In the method, the input audio is first divided into short blocks, then attractor-based diarization is performed for each block, and finally the results of each blocks are clustered on the basis of the similarity between locally-calculated attractors. While the number of output speakers is limited within each block, the total number of speakers estimated for the entire input can be higher than the limitation. To use EEND-GLA in an online manner, our method also extends the speaker-tracing buffer, which was originally proposed to enable online inference of conventional EEND. We introduce a block-wise buffer update to make the speaker-tracing buffer compatible with EEND-GLA. Finally, to improve online diarization, our method improves the buffer update method and revisits the variable chunk-size training of EEND. The experimental results demonstrate that EEND-GLA can perform speaker diarization of an unseen number of speakers in both offline and online inferences.},
    html={https://ieeexplore.ieee.org/document/10003998},
    arxiv={2206.02432},
    comment={üèÜ IEEE SPS Japan Young Author Best Paper Award},
    selected={true}
}
@article{horiguchi2022encoderdecoder,
    title={Encoder-Decoder Based Attractors for End-to-End Neural Diarization},
    journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
    author={Horiguchi, Shota and Fujita, Yusuke and Watanabe, Shinji and Xue, Yawen  and Garc{\'i}a, Paola},
    volume={30},
    year={2022},
    month=mar,
    pages={1493--1507},
    keywords={first},
    abbr={TASLP},
    abstract={This paper investigates an end-to-end neural diarization (EEND) method for an unknown number of speakers. In contrast to the conventional cascaded approach to speaker diarization, EEND methods are better in terms of speaker overlap handling. However, EEND still has a disadvantage in that it cannot deal with a flexible number of speakers. To remedy this problem, we introduce encoder-decoder-based attractor calculation module (EDA) to EEND. Once frame-wise embeddings are obtained, EDA sequentially generates speaker-wise attractors on the basis of a sequence-to-sequence method using an LSTM encoder-decoder. The attractor generation continues until a stopping condition is satisfied; thus, the number of attractors can be flexible. Diarization results are then estimated as dot products of the attractors and embeddings. The embeddings from speaker overlaps result in larger dot product values with multiple attractors; thus, this method can deal with speaker overlaps. Because the maximum number of output speakers is still limited by the training set, we also propose an iterative inference method to remove this restriction. Further, we propose a method that aligns the estimated diarization results with the results of an external speech activity detector, which enables fair comparison against cascaded approaches. Extensive evaluations on simulated and real datasets show that EEND-EDA outperforms the conventional cascaded approach.},
    html={https://ieeexplore.ieee.org/document/9741374},
    arxiv={2106.10654},
    comment={üèÜ IEEE SPS Young Author Best Paper Award<br />üèÜ Itakura Prize Innovative Young Researcher Award},
    selected={true}
}

@article{horiguchi2020significance,
    title = {Significance of Softmax-based Features in Comparison to Distance Metric Learning-based Features},
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
    author={Horiguchi, Shota and Ikami, Daiki and Aizawa, Kiyoharu},
    volume={42},
    number={5},
    year={2020},
    month=may,
    pages={1279--1285},
    keywords={first},
    abbr={TPAMI},
    abstract={End-to-end distance metric learning (DML) has been applied to obtain features useful in many computer vision tasks. However, these DML studies have not provided equitable comparisons between features extracted from DML-based networks and softmax-based networks. In this paper, we present objective comparisons between these two approaches under the same network architecture.},
    html={https://ieeexplore.ieee.org/document/8691614},
    arxiv={1712.10151},
    selected={true}
}

@article{horiguchi2018personalized,
    title={Personalized Classifier for Food Image Recognition},
    journal={IEEE Transactions on Multimedia},
    author={Horiguchi, Shota and Amano, Sosuke and Ogawa, Makoto and Aizawa, Kiyoharu},
    volume={20},
    number={10},
    year={2018},
    month=oct,
    pages={2836--2848},
    keywords={first},
    abbr={TMM},
    abstract={Currently, food image recognition tasks are evaluated against fixed datasets. However, in real-world conditions, there are cases in which the number of samples in each class continues to increase and samples from novel classes appear. In particular, dynamic datasets in which each individual user creates samples and continues the updating process often has content that varies considerably between different users, and the number of samples per person is very limited. A single classifier common to all users cannot handle such dynamic data. Bridging the gap between the laboratory environment and the real world has not yet been accomplished on a large scale. Personalizing a classifier incrementally for each user is a promising way to do this. In this paper, we address the personalization problem, which involves adapting to the user's domain incrementally using a very limited number of samples. We propose a simple yet effective personalization framework, which is a combination of the nearest class mean classifier and the 1-nearest neighbor classifier based on deep features. To conduct realistic experiments, we made use of a new dataset of daily food images collected by a food-logging application. Experimental results show that our proposed method significantly outperforms existing methods.},
    html={https://ieeexplore.ieee.org/document/8316919},
    arxiv={1804.04600},
    selected={true}
}

% Co-author
@article{kamo2026microphone,
    title={Microphone Array Geometry Independent Multi-Talker Distant {ASR}: {NTT} System for the {DASR} Task of the {CHiME}-8 Challenge},
    journal={Computer Speech & Language},
    author={Kamo, Naoyuki and Tawara, Naohiro and Ando, Atsushi and Kano, Takatomo and Sato, Hiroshi and Ikeshita, Rintaro and Moriya, Takafumi and Horiguchi, Shota and Matsuura, Kohei and Ogawa, Atsunori and Plaquet, Alexis and Ashihara, Takanori and Ochiai, Tsubasa and Mimura, Masato and Delcroix, Marc and Nakatani, Tomohiro and Asami, Taichi and Araki, Shoko},
    volume={95},
    pages={101820},
    year={2026},
    month=jan,
    pages={101820},
    abbr={CSL},
    abstract={In this paper, we introduce a multi-talker distant automatic speech recognition (DASR) system we designed for the DASR task 1 of the CHiME-8 challenge. Our system performs speaker counting, diarization, and ASR. It handles a variety of recording conditions, from dinner parties to professional meetings and from two speakers to eight. We perform diarization first, followed by speech enhancement, and then ASR as the challenge baseline. However, we introduced several key refinements. First, we derived a powerful speaker diarization relying on end-to-end speaker diarization with vector clustering (EEND-VC), multi-channel speaker counting using enhanced embeddings from EEND-VC, and target-speaker voice activity detection (TS-VAD). For speech enhancement, we introduced a novel microphone selection rule to better select the most relevant microphones among those distributed microphones and investigated improvements to beamforming. Finally, for ASR, we developed several models exploiting Whisper and WavLM speech foundation models. In this paper, we present the original results we submitted to the challenge and updated results we obtained afterward. Our strongest system achieves a 63\% relative macro tcpWER improvement over the baseline and outperforms the challenge best results on the NOTSOFAR-1 meeting evaluation data among geometry-independent systems.},
    html={https://www.sciencedirect.com/science/article/pii/S0885230825000452},
    arxiv={2502.09859}
}
